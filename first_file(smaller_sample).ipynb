{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_file(smaller sample).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnrb/word2vec_char_level/blob/master/first_file(smaller_sample).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "e6V9UZs3ZgVz",
        "colab_type": "code",
        "outputId": "ab0442a3-8ace-4e4f-fd82-8bbe8236b25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dnrb/word2vec_char_level.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'word2vec_char_level'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 38 (delta 16), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (38/38), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BYaN6r95aBe9",
        "colab_type": "code",
        "outputId": "3633a0a8-532a-45f9-8a8a-db3d94d86bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  word2vec_char_level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c79oIA2xaJZs",
        "colab_type": "code",
        "outputId": "2c83185f-1dd0-45fd-defe-ade484bd2285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd word2vec_char_level"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/word2vec_char_level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTMzA1TIaQW4",
        "colab_type": "code",
        "outputId": "426d351f-83ac-48da-ef32-407a119da2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " first_file.ipynb\t\t     README.md\t  tasa_2.txt\n",
            "'first_file(smaller_sample).ipynb'   tasa_1.txt   tasa_3.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_5CTTY49bs3B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Read the input file**"
      ]
    },
    {
      "metadata": {
        "id": "ZeokAW7caRsK",
        "colab_type": "code",
        "outputId": "57de7ab7-b097-4b3c-f040-506357cda5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file  = 'tasa_1.txt'\n",
        "filehandle = open(file)\n",
        "lines  = filehandle.readlines()\n",
        "len(lines)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "cDSBuQYLbnId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set up the corpus**"
      ]
    },
    {
      "metadata": {
        "id": "p3mAZUAxbkfX",
        "colab_type": "code",
        "outputId": "eca9dfc4-3cca-447c-90cb-e7d639a44ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "corpus = lines[:10]\n",
        "print(corpus)\n",
        "len(corpus)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['who were the first americans ?\\n', 'many , many years ago , perhaps 35,000 years ago , life was very different than it is today .\\n', 'at that time , the earth was in the grip of the last ice age .\\n', 'there were few people anywhere in the world , and none lived in the americas .\\n', 'people did live in asia , however .\\n', 'and some of them wandered into north america .\\n', 'the firstcomers did not know they had found a new continent .\\n', 'like all ice age peoples , they were hunters .\\n', 'they had to move from place to place in search of their food .\\n', 'sometimes they killed giant elephants called mammoths .\\n']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "QIKrn8PDcAeD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus = [x[:-3] for x in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snsuFqGTdVO4",
        "colab_type": "code",
        "outputId": "e3a2ab28-7b83-4180-aaf9-d3e2f6213705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59
        }
      },
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['who were the first american', 'many , many years ago , perhaps 35,000 years ago , life was very different than it is toda', 'at that time , the earth was in the grip of the last ice ag', 'there were few people anywhere in the world , and none lived in the america', 'people did live in asia , howeve', 'and some of them wandered into north americ', 'the firstcomers did not know they had found a new continen', 'like all ice age peoples , they were hunter', 'they had to move from place to place in search of their foo', 'sometimes they killed giant elephants called mammoth']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mZkVDs_IgXaq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Gather every words in the corpus**"
      ]
    },
    {
      "metadata": {
        "id": "E_c8-FoNeo9Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "words = []\n",
        "\n",
        "for sentence in corpus:\n",
        "    \n",
        "    for word in sentence.split(' '):\n",
        "        \n",
        "        if word not in string.punctuation:\n",
        "            words.append(word)\n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrfxCx4AfF_1",
        "colab_type": "code",
        "outputId": "ccea1f7e-61fd-4737-b75b-ba7b0bec89df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "ZhA_JrEPh2lv",
        "colab_type": "code",
        "outputId": "2761d3a0-a088-4366-b91e-149968c7afb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "cell_type": "code",
      "source": [
        "words"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['who',\n",
              " 'were',\n",
              " 'the',\n",
              " 'first',\n",
              " 'american',\n",
              " 'many',\n",
              " 'many',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'perhaps',\n",
              " '35,000',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'life',\n",
              " 'was',\n",
              " 'very',\n",
              " 'different',\n",
              " 'than',\n",
              " 'it',\n",
              " 'is',\n",
              " 'toda',\n",
              " 'at',\n",
              " 'that',\n",
              " 'time',\n",
              " 'the',\n",
              " 'earth',\n",
              " 'was',\n",
              " 'in',\n",
              " 'the',\n",
              " 'grip',\n",
              " 'of',\n",
              " 'the',\n",
              " 'last',\n",
              " 'ice',\n",
              " 'ag',\n",
              " 'there',\n",
              " 'were',\n",
              " 'few',\n",
              " 'people',\n",
              " 'anywhere',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world',\n",
              " 'and',\n",
              " 'none',\n",
              " 'lived',\n",
              " 'in',\n",
              " 'the',\n",
              " 'america',\n",
              " 'people',\n",
              " 'did',\n",
              " 'live',\n",
              " 'in',\n",
              " 'asia',\n",
              " 'howeve',\n",
              " 'and',\n",
              " 'some',\n",
              " 'of',\n",
              " 'them',\n",
              " 'wandered',\n",
              " 'into',\n",
              " 'north',\n",
              " 'americ',\n",
              " 'the',\n",
              " 'firstcomers',\n",
              " 'did',\n",
              " 'not',\n",
              " 'know',\n",
              " 'they',\n",
              " 'had',\n",
              " 'found',\n",
              " 'a',\n",
              " 'new',\n",
              " 'continen',\n",
              " 'like',\n",
              " 'all',\n",
              " 'ice',\n",
              " 'age',\n",
              " 'peoples',\n",
              " 'they',\n",
              " 'were',\n",
              " 'hunter',\n",
              " 'they',\n",
              " 'had',\n",
              " 'to',\n",
              " 'move',\n",
              " 'from',\n",
              " 'place',\n",
              " 'to',\n",
              " 'place',\n",
              " 'in',\n",
              " 'search',\n",
              " 'of',\n",
              " 'their',\n",
              " 'foo',\n",
              " 'sometimes',\n",
              " 'they',\n",
              " 'killed',\n",
              " 'giant',\n",
              " 'elephants',\n",
              " 'called',\n",
              " 'mammoth']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "DEPbxBRsj7OP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convert text to int**"
      ]
    },
    {
      "metadata": {
        "id": "QE906jcGniIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def str_to_int(lst):\n",
        "    counter = 1\n",
        "    new_list = []\n",
        "    existed = {}\n",
        "    \n",
        "    for string in lst:\n",
        "        if string not in existed:\n",
        "            existed[string] = counter\n",
        "            new_list.append(existed[string])\n",
        "            counter += 1\n",
        "        else:\n",
        "            new_list.append(existed[string])\n",
        "            \n",
        "    return new_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7yRwd5_oGFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "6aeb1179-9000-42e6-ee97-74ce760a80fe"
      },
      "cell_type": "code",
      "source": [
        "str_to_int(words)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 7,\n",
              " 8,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 3,\n",
              " 22,\n",
              " 12,\n",
              " 23,\n",
              " 3,\n",
              " 24,\n",
              " 25,\n",
              " 3,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 2,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 23,\n",
              " 3,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 23,\n",
              " 3,\n",
              " 37,\n",
              " 31,\n",
              " 38,\n",
              " 39,\n",
              " 23,\n",
              " 40,\n",
              " 41,\n",
              " 34,\n",
              " 42,\n",
              " 25,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 3,\n",
              " 48,\n",
              " 38,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 27,\n",
              " 59,\n",
              " 60,\n",
              " 51,\n",
              " 2,\n",
              " 61,\n",
              " 51,\n",
              " 52,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 62,\n",
              " 65,\n",
              " 23,\n",
              " 66,\n",
              " 25,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 51,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "GsrciQlRjrK_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(cleaned_words):\n",
        "    word2int[word] = i\n",
        "\n",
        "sentences = []\n",
        "for sentence in corpus:\n",
        "    sentences.append(sentence.split())\n",
        "    \n",
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "            if neighbor != word:\n",
        "                data.append([word, neighbor])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bz2sK5LwkBYn",
        "colab_type": "code",
        "outputId": "305568c8-d731-4223-f484-5b111691b482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7021
        }
      },
      "cell_type": "code",
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['who', 'were'],\n",
              " ['who', 'the'],\n",
              " ['were', 'who'],\n",
              " ['were', 'the'],\n",
              " ['were', 'first'],\n",
              " ['the', 'who'],\n",
              " ['the', 'were'],\n",
              " ['the', 'first'],\n",
              " ['the', 'americans'],\n",
              " ['first', 'were'],\n",
              " ['first', 'the'],\n",
              " ['first', 'americans'],\n",
              " ['first', '?'],\n",
              " ['americans', 'the'],\n",
              " ['americans', 'first'],\n",
              " ['americans', '?'],\n",
              " ['?', 'first'],\n",
              " ['?', 'americans'],\n",
              " ['many', ','],\n",
              " [',', 'many'],\n",
              " [',', 'many'],\n",
              " [',', 'years'],\n",
              " ['many', ','],\n",
              " ['many', 'years'],\n",
              " ['many', 'ago'],\n",
              " ['years', ','],\n",
              " ['years', 'many'],\n",
              " ['years', 'ago'],\n",
              " ['years', ','],\n",
              " ['ago', 'many'],\n",
              " ['ago', 'years'],\n",
              " ['ago', ','],\n",
              " ['ago', 'perhaps'],\n",
              " [',', 'years'],\n",
              " [',', 'ago'],\n",
              " [',', 'perhaps'],\n",
              " [',', '35,000'],\n",
              " ['perhaps', 'ago'],\n",
              " ['perhaps', ','],\n",
              " ['perhaps', '35,000'],\n",
              " ['perhaps', 'years'],\n",
              " ['35,000', ','],\n",
              " ['35,000', 'perhaps'],\n",
              " ['35,000', 'years'],\n",
              " ['35,000', 'ago'],\n",
              " ['years', 'perhaps'],\n",
              " ['years', '35,000'],\n",
              " ['years', 'ago'],\n",
              " ['years', ','],\n",
              " ['ago', '35,000'],\n",
              " ['ago', 'years'],\n",
              " ['ago', ','],\n",
              " ['ago', 'life'],\n",
              " [',', 'years'],\n",
              " [',', 'ago'],\n",
              " [',', 'life'],\n",
              " [',', 'was'],\n",
              " ['life', 'ago'],\n",
              " ['life', ','],\n",
              " ['life', 'was'],\n",
              " ['life', 'very'],\n",
              " ['was', ','],\n",
              " ['was', 'life'],\n",
              " ['was', 'very'],\n",
              " ['was', 'different'],\n",
              " ['very', 'life'],\n",
              " ['very', 'was'],\n",
              " ['very', 'different'],\n",
              " ['very', 'than'],\n",
              " ['different', 'was'],\n",
              " ['different', 'very'],\n",
              " ['different', 'than'],\n",
              " ['different', 'it'],\n",
              " ['than', 'very'],\n",
              " ['than', 'different'],\n",
              " ['than', 'it'],\n",
              " ['than', 'is'],\n",
              " ['it', 'different'],\n",
              " ['it', 'than'],\n",
              " ['it', 'is'],\n",
              " ['it', 'today'],\n",
              " ['is', 'than'],\n",
              " ['is', 'it'],\n",
              " ['is', 'today'],\n",
              " ['is', '.'],\n",
              " ['today', 'it'],\n",
              " ['today', 'is'],\n",
              " ['today', '.'],\n",
              " ['.', 'is'],\n",
              " ['.', 'today'],\n",
              " ['at', 'that'],\n",
              " ['at', 'time'],\n",
              " ['that', 'at'],\n",
              " ['that', 'time'],\n",
              " ['that', ','],\n",
              " ['time', 'at'],\n",
              " ['time', 'that'],\n",
              " ['time', ','],\n",
              " ['time', 'the'],\n",
              " [',', 'that'],\n",
              " [',', 'time'],\n",
              " [',', 'the'],\n",
              " [',', 'earth'],\n",
              " ['the', 'time'],\n",
              " ['the', ','],\n",
              " ['the', 'earth'],\n",
              " ['the', 'was'],\n",
              " ['earth', ','],\n",
              " ['earth', 'the'],\n",
              " ['earth', 'was'],\n",
              " ['earth', 'in'],\n",
              " ['was', 'the'],\n",
              " ['was', 'earth'],\n",
              " ['was', 'in'],\n",
              " ['was', 'the'],\n",
              " ['in', 'earth'],\n",
              " ['in', 'was'],\n",
              " ['in', 'the'],\n",
              " ['in', 'grip'],\n",
              " ['the', 'was'],\n",
              " ['the', 'in'],\n",
              " ['the', 'grip'],\n",
              " ['the', 'of'],\n",
              " ['grip', 'in'],\n",
              " ['grip', 'the'],\n",
              " ['grip', 'of'],\n",
              " ['grip', 'the'],\n",
              " ['of', 'the'],\n",
              " ['of', 'grip'],\n",
              " ['of', 'the'],\n",
              " ['of', 'last'],\n",
              " ['the', 'grip'],\n",
              " ['the', 'of'],\n",
              " ['the', 'last'],\n",
              " ['the', 'ice'],\n",
              " ['last', 'of'],\n",
              " ['last', 'the'],\n",
              " ['last', 'ice'],\n",
              " ['last', 'age'],\n",
              " ['ice', 'the'],\n",
              " ['ice', 'last'],\n",
              " ['ice', 'age'],\n",
              " ['ice', '.'],\n",
              " ['age', 'last'],\n",
              " ['age', 'ice'],\n",
              " ['age', '.'],\n",
              " ['.', 'ice'],\n",
              " ['.', 'age'],\n",
              " ['there', 'were'],\n",
              " ['there', 'few'],\n",
              " ['were', 'there'],\n",
              " ['were', 'few'],\n",
              " ['were', 'people'],\n",
              " ['few', 'there'],\n",
              " ['few', 'were'],\n",
              " ['few', 'people'],\n",
              " ['few', 'anywhere'],\n",
              " ['people', 'were'],\n",
              " ['people', 'few'],\n",
              " ['people', 'anywhere'],\n",
              " ['people', 'in'],\n",
              " ['anywhere', 'few'],\n",
              " ['anywhere', 'people'],\n",
              " ['anywhere', 'in'],\n",
              " ['anywhere', 'the'],\n",
              " ['in', 'people'],\n",
              " ['in', 'anywhere'],\n",
              " ['in', 'the'],\n",
              " ['in', 'world'],\n",
              " ['the', 'anywhere'],\n",
              " ['the', 'in'],\n",
              " ['the', 'world'],\n",
              " ['the', ','],\n",
              " ['world', 'in'],\n",
              " ['world', 'the'],\n",
              " ['world', ','],\n",
              " ['world', 'and'],\n",
              " [',', 'the'],\n",
              " [',', 'world'],\n",
              " [',', 'and'],\n",
              " [',', 'none'],\n",
              " ['and', 'world'],\n",
              " ['and', ','],\n",
              " ['and', 'none'],\n",
              " ['and', 'lived'],\n",
              " ['none', ','],\n",
              " ['none', 'and'],\n",
              " ['none', 'lived'],\n",
              " ['none', 'in'],\n",
              " ['lived', 'and'],\n",
              " ['lived', 'none'],\n",
              " ['lived', 'in'],\n",
              " ['lived', 'the'],\n",
              " ['in', 'none'],\n",
              " ['in', 'lived'],\n",
              " ['in', 'the'],\n",
              " ['in', 'americas'],\n",
              " ['the', 'lived'],\n",
              " ['the', 'in'],\n",
              " ['the', 'americas'],\n",
              " ['the', '.'],\n",
              " ['americas', 'in'],\n",
              " ['americas', 'the'],\n",
              " ['americas', '.'],\n",
              " ['.', 'the'],\n",
              " ['.', 'americas'],\n",
              " ['people', 'did'],\n",
              " ['people', 'live'],\n",
              " ['did', 'people'],\n",
              " ['did', 'live'],\n",
              " ['did', 'in'],\n",
              " ['live', 'people'],\n",
              " ['live', 'did'],\n",
              " ['live', 'in'],\n",
              " ['live', 'asia'],\n",
              " ['in', 'did'],\n",
              " ['in', 'live'],\n",
              " ['in', 'asia'],\n",
              " ['in', ','],\n",
              " ['asia', 'live'],\n",
              " ['asia', 'in'],\n",
              " ['asia', ','],\n",
              " ['asia', 'however'],\n",
              " [',', 'in'],\n",
              " [',', 'asia'],\n",
              " [',', 'however'],\n",
              " [',', '.'],\n",
              " ['however', 'asia'],\n",
              " ['however', ','],\n",
              " ['however', '.'],\n",
              " ['.', ','],\n",
              " ['.', 'however'],\n",
              " ['and', 'some'],\n",
              " ['and', 'of'],\n",
              " ['some', 'and'],\n",
              " ['some', 'of'],\n",
              " ['some', 'them'],\n",
              " ['of', 'and'],\n",
              " ['of', 'some'],\n",
              " ['of', 'them'],\n",
              " ['of', 'wandered'],\n",
              " ['them', 'some'],\n",
              " ['them', 'of'],\n",
              " ['them', 'wandered'],\n",
              " ['them', 'into'],\n",
              " ['wandered', 'of'],\n",
              " ['wandered', 'them'],\n",
              " ['wandered', 'into'],\n",
              " ['wandered', 'north'],\n",
              " ['into', 'them'],\n",
              " ['into', 'wandered'],\n",
              " ['into', 'north'],\n",
              " ['into', 'america'],\n",
              " ['north', 'wandered'],\n",
              " ['north', 'into'],\n",
              " ['north', 'america'],\n",
              " ['north', '.'],\n",
              " ['america', 'into'],\n",
              " ['america', 'north'],\n",
              " ['america', '.'],\n",
              " ['.', 'north'],\n",
              " ['.', 'america'],\n",
              " ['the', 'firstcomers'],\n",
              " ['the', 'did'],\n",
              " ['firstcomers', 'the'],\n",
              " ['firstcomers', 'did'],\n",
              " ['firstcomers', 'not'],\n",
              " ['did', 'the'],\n",
              " ['did', 'firstcomers'],\n",
              " ['did', 'not'],\n",
              " ['did', 'know'],\n",
              " ['not', 'firstcomers'],\n",
              " ['not', 'did'],\n",
              " ['not', 'know'],\n",
              " ['not', 'they'],\n",
              " ['know', 'did'],\n",
              " ['know', 'not'],\n",
              " ['know', 'they'],\n",
              " ['know', 'had'],\n",
              " ['they', 'not'],\n",
              " ['they', 'know'],\n",
              " ['they', 'had'],\n",
              " ['they', 'found'],\n",
              " ['had', 'know'],\n",
              " ['had', 'they'],\n",
              " ['had', 'found'],\n",
              " ['had', 'a'],\n",
              " ['found', 'they'],\n",
              " ['found', 'had'],\n",
              " ['found', 'a'],\n",
              " ['found', 'new'],\n",
              " ['a', 'had'],\n",
              " ['a', 'found'],\n",
              " ['a', 'new'],\n",
              " ['a', 'continent'],\n",
              " ['new', 'found'],\n",
              " ['new', 'a'],\n",
              " ['new', 'continent'],\n",
              " ['new', '.'],\n",
              " ['continent', 'a'],\n",
              " ['continent', 'new'],\n",
              " ['continent', '.'],\n",
              " ['.', 'new'],\n",
              " ['.', 'continent'],\n",
              " ['like', 'all'],\n",
              " ['like', 'ice'],\n",
              " ['all', 'like'],\n",
              " ['all', 'ice'],\n",
              " ['all', 'age'],\n",
              " ['ice', 'like'],\n",
              " ['ice', 'all'],\n",
              " ['ice', 'age'],\n",
              " ['ice', 'peoples'],\n",
              " ['age', 'all'],\n",
              " ['age', 'ice'],\n",
              " ['age', 'peoples'],\n",
              " ['age', ','],\n",
              " ['peoples', 'ice'],\n",
              " ['peoples', 'age'],\n",
              " ['peoples', ','],\n",
              " ['peoples', 'they'],\n",
              " [',', 'age'],\n",
              " [',', 'peoples'],\n",
              " [',', 'they'],\n",
              " [',', 'were'],\n",
              " ['they', 'peoples'],\n",
              " ['they', ','],\n",
              " ['they', 'were'],\n",
              " ['they', 'hunters'],\n",
              " ['were', ','],\n",
              " ['were', 'they'],\n",
              " ['were', 'hunters'],\n",
              " ['were', '.'],\n",
              " ['hunters', 'they'],\n",
              " ['hunters', 'were'],\n",
              " ['hunters', '.'],\n",
              " ['.', 'were'],\n",
              " ['.', 'hunters'],\n",
              " ['they', 'had'],\n",
              " ['they', 'to'],\n",
              " ['had', 'they'],\n",
              " ['had', 'to'],\n",
              " ['had', 'move'],\n",
              " ['to', 'they'],\n",
              " ['to', 'had'],\n",
              " ['to', 'move'],\n",
              " ['to', 'from'],\n",
              " ['move', 'had'],\n",
              " ['move', 'to'],\n",
              " ['move', 'from'],\n",
              " ['move', 'place'],\n",
              " ['from', 'to'],\n",
              " ['from', 'move'],\n",
              " ['from', 'place'],\n",
              " ['from', 'to'],\n",
              " ['place', 'move'],\n",
              " ['place', 'from'],\n",
              " ['place', 'to'],\n",
              " ['to', 'from'],\n",
              " ['to', 'place'],\n",
              " ['to', 'place'],\n",
              " ['to', 'in'],\n",
              " ['place', 'to'],\n",
              " ['place', 'in'],\n",
              " ['place', 'search'],\n",
              " ['in', 'to'],\n",
              " ['in', 'place'],\n",
              " ['in', 'search'],\n",
              " ['in', 'of'],\n",
              " ['search', 'place'],\n",
              " ['search', 'in'],\n",
              " ['search', 'of'],\n",
              " ['search', 'their'],\n",
              " ['of', 'in'],\n",
              " ['of', 'search'],\n",
              " ['of', 'their'],\n",
              " ['of', 'food'],\n",
              " ['their', 'search'],\n",
              " ['their', 'of'],\n",
              " ['their', 'food'],\n",
              " ['their', '.'],\n",
              " ['food', 'of'],\n",
              " ['food', 'their'],\n",
              " ['food', '.'],\n",
              " ['.', 'their'],\n",
              " ['.', 'food'],\n",
              " ['sometimes', 'they'],\n",
              " ['sometimes', 'killed'],\n",
              " ['they', 'sometimes'],\n",
              " ['they', 'killed'],\n",
              " ['they', 'giant'],\n",
              " ['killed', 'sometimes'],\n",
              " ['killed', 'they'],\n",
              " ['killed', 'giant'],\n",
              " ['killed', 'elephants'],\n",
              " ['giant', 'they'],\n",
              " ['giant', 'killed'],\n",
              " ['giant', 'elephants'],\n",
              " ['giant', 'called'],\n",
              " ['elephants', 'killed'],\n",
              " ['elephants', 'giant'],\n",
              " ['elephants', 'called'],\n",
              " ['elephants', 'mammoths'],\n",
              " ['called', 'giant'],\n",
              " ['called', 'elephants'],\n",
              " ['called', 'mammoths'],\n",
              " ['called', '.'],\n",
              " ['mammoths', 'elephants'],\n",
              " ['mammoths', 'called'],\n",
              " ['mammoths', '.'],\n",
              " ['.', 'called'],\n",
              " ['.', 'mammoths']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "o2cywu4ZkfWC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AbStdR81hqG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Remove stop words**"
      ]
    },
    {
      "metadata": {
        "id": "Jkxl31icfHhR",
        "colab_type": "code",
        "outputId": "7717ec60-4ce5-4de0-e87a-7a90bb6e18dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "AWwiM2zmhxpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "cleaned_words = []\n",
        "\n",
        "for word in words:\n",
        "    if word not in stopwords:\n",
        "        cleaned_words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}