{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_file(English Model).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnrb/word2vec_char_level/blob/master/first_file(English_Model).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6V9UZs3ZgVz",
        "colab_type": "code",
        "outputId": "60112eb5-2797-470a-8917-d9f5066b177a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "!git clone https://github.com/dnrb/word2vec_char_level.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'word2vec_char_level'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 59 (delta 27), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyRbXe5_otJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "b94358ce-084d-473e-c91e-bb1e82440373"
      },
      "source": [
        "cd word2vec_char_level/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/word2vec_char_level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXDWSvj7oZ-p",
        "colab_type": "text"
      },
      "source": [
        "**Verify the first data file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoSiGjZnofQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "85ad5f52-bcf3-4d53-b0e8-be5fb7ae027a"
      },
      "source": [
        "file1 = 'tasa_1.txt'\n",
        "filehandle1 = open(file1)\n",
        "lines1 = filehandle1.readlines()\n",
        "len(lines1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTKTj7zCo0Ms",
        "colab_type": "text"
      },
      "source": [
        "**Verify the second data file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hnhcQQTo_f9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "29e44c8e-ef6d-4739-a811-06c02248da5f"
      },
      "source": [
        "file2 = 'tasa_2.txt'\n",
        "filehandle2 = open(file2)\n",
        "lines2 = filehandle2.readlines()\n",
        "len(lines2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbyehl1Bo73Y",
        "colab_type": "text"
      },
      "source": [
        "**Verify the third data file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwLgVDBapEZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "006b2266-4108-4912-a36b-cdb9cd466445"
      },
      "source": [
        "file3 = 'tasa_3.txt'\n",
        "filehandle3 = open(file1)\n",
        "lines3 = filehandle3.readlines()\n",
        "len(lines3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aocpMO_0pJLT",
        "colab_type": "text"
      },
      "source": [
        "**Construct the corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xYhUcR1pMAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "a5d1eba2-c9d7-44d4-ce70-aa386c1cf9f2"
      },
      "source": [
        "corpus = lines1 + lines2 + lines3\n",
        "len(corpus)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "750000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZkVDs_IgXaq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "**Gather every words in the corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_c8-FoNeo9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "words = []\n",
        "\n",
        "for sentence in corpus:\n",
        "    \n",
        "    for word in sentence.split(' '):\n",
        "        \n",
        "        if word not in string.punctuation:\n",
        "            words.append(word)\n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrfxCx4AfF_1",
        "colab_type": "code",
        "outputId": "9896a41a-916f-41fe-d597-fc7f7184a041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11556159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhA_JrEPh2lv",
        "colab_type": "code",
        "outputId": "8050ecd1-6a10-47d4-c113-ba25ac284c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "words[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['who',\n",
              " 'were',\n",
              " 'the',\n",
              " 'first',\n",
              " 'americans',\n",
              " '?\\n',\n",
              " 'many',\n",
              " 'many',\n",
              " 'years',\n",
              " 'ago']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxgD5t8w_pWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_set = set(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEPbxBRsj7OP",
        "colab_type": "text"
      },
      "source": [
        "**Convert text to int**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE906jcGniIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def str_to_int(lst):\n",
        "    counter = 0\n",
        "    new_list = []\n",
        "    existed = {}\n",
        "    \n",
        "    for string in lst:\n",
        "        if string not in existed:\n",
        "            existed[string] = counter\n",
        "            new_list.append(existed[string])\n",
        "            counter += 1\n",
        "        else:\n",
        "            new_list.append(existed[string])\n",
        "            \n",
        "    return new_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7yRwd5_oGFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2int = str_to_int(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b6VzicdmLaj",
        "colab_type": "code",
        "outputId": "b49c0242-11f8-4638-f3bf-5152135502ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "min(word2int)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1MCjMpCmObf",
        "colab_type": "code",
        "outputId": "7aec6e54-189b-40dc-983d-a0030143878a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "max(word2int)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95209"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJXwKZXXmTGL",
        "colab_type": "text"
      },
      "source": [
        "**Set up the constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxY46f26mWkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_Train = 50\n",
        "n_Voc = max(word2int) + 1\n",
        "n_Corpus = len(word2int)\n",
        "WINDOW_SIZE = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXJxY79toOti",
        "colab_type": "code",
        "outputId": "03cb1068-8d42-4a1d-961c-a807b4dbd4fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "n_Voc"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95210"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCJEVyNMeyGd",
        "colab_type": "text"
      },
      "source": [
        "**Initialize two arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJQ8yuhhexKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int):\n",
        "\n",
        "    X = np.zeros((n_Train, n_Voc))\n",
        "    Y = np.zeros((n_Train, n_Voc))\n",
        "\n",
        "    for i in range(n_Train):\n",
        "        j = np.random.choice(n_Corpus, 1)[0]\n",
        "\n",
        "        tw = word2int[j]\n",
        "\n",
        "        Y[i][tw] = 1\n",
        "\n",
        "        for k in range(j - WINDOW_SIZE, j + WINDOW_SIZE + 1):\n",
        "            if k != j and k >= 0 and k < n_Corpus:\n",
        "                cw = word2int[k]\n",
        "                X[i][cw] = 1\n",
        "                \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDEFW_v7oPXE",
        "colab_type": "code",
        "outputId": "563dbf43-125a-4d90-903a-2324646309c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SisXlsDQYhs",
        "colab_type": "code",
        "outputId": "5f90437c-b1af-4a05-d873-5f199f2a2ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "ONE_HOT_DIM = n_Voc\n",
        "\n",
        "# # function to convert numbers to one hot vectors\n",
        "# def to_one_hot_encoding(data_point_index):\n",
        "#     one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
        "#     one_hot_encoding[data_point_index] = 1\n",
        "#     return one_hot_encoding\n",
        "\n",
        "# X = [] # input word\n",
        "# Y = [] # target word\n",
        "\n",
        "# for x, y in zip(df['input'], df['label']):\n",
        "#     X.append(to_one_hot_encoding(word2int[ x ]))\n",
        "#     Y.append(to_one_hot_encoding(word2int[ y ]))\n",
        "\n",
        "# # convert them to numpy arrays\n",
        "# X_train = np.asarray(X)\n",
        "# Y_train = np.asarray(Y)\n",
        "\n",
        "# making placeholders for X_train and Y_train\n",
        "x = tf.placeholder(tf.float64, shape=(None, ONE_HOT_DIM))\n",
        "y_label = tf.placeholder(tf.float64, shape=(None, ONE_HOT_DIM))\n",
        "\n",
        "# word embedding will be 2 dimension for 2d visualization\n",
        "EMBEDDING_DIM = 30\n",
        "\n",
        "# hidden layer: which represents word vector eventually\n",
        "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM], dtype=tf.float64))\n",
        "b1 = tf.Variable(tf.random_normal([1], dtype=tf.float64)) #bias\n",
        "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
        "\n",
        "# output layer\n",
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM], dtype=tf.float64))\n",
        "b2 = tf.Variable(tf.random_normal([1], dtype=tf.float64))\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
        "\n",
        "# loss function: cross entropy\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
        "\n",
        "# training operation(learning rate)\n",
        "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2cywu4ZkfWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sUhj1mHiR_G",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPC4y_0biUKj",
        "colab_type": "code",
        "outputId": "e734099c-42c9-4a35-c3c1-e2782d5d5afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init) \n",
        "\n",
        "iteration = 20000\n",
        "for i in range(iteration + 1):\n",
        "    X, Y = data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int)\n",
        "    # input is X_train which is one hot encoded word\n",
        "    # label is Y_train which is one hot encoded neighbor word\n",
        "    sess.run(train_op, feed_dict={x: X, y_label: Y})\n",
        "    if i % 500 == 0:\n",
        "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X, y_label: Y}))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0 loss is :  47.185211897620704\n",
            "iteration 500 loss is :  37.194145890825425\n",
            "iteration 1000 loss is :  34.08522663068314\n",
            "iteration 1500 loss is :  30.99789962617716\n",
            "iteration 2000 loss is :  31.618508257170603\n",
            "iteration 2500 loss is :  26.706190519584755\n",
            "iteration 3000 loss is :  24.5662889929537\n",
            "iteration 3500 loss is :  25.729650847766823\n",
            "iteration 4000 loss is :  26.989030869512522\n",
            "iteration 4500 loss is :  25.086860629470333\n",
            "iteration 5000 loss is :  25.716319344143226\n",
            "iteration 5500 loss is :  24.089234606563696\n",
            "iteration 6000 loss is :  23.981382152955735\n",
            "iteration 6500 loss is :  22.920383605277088\n",
            "iteration 7000 loss is :  23.444663737750282\n",
            "iteration 7500 loss is :  18.196834042602333\n",
            "iteration 8000 loss is :  20.653580463399816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1201ffd3d642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# input is X_train which is one hot encoded word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# label is Y_train which is one hot encoded neighbor word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' loss is : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFz_OdtJiuqo",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1j81pDCit4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "Z = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "Z_embedded = TSNE(n_components=2).fit_transform(Z)\n",
        "Z_embedded.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfzzBYgr-9El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = sess.run(W1 + b1)\n",
        "vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecEmg_b2Gsfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector_embedded_2d = TSNE(perplexity=100).fit_transform(vectors)\n",
        "vector_embedded_2d.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9-p5RdskEKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRqvW4jZGnkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tsne_plot_2d(label, embeddings, words=[], a=1):\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    colors = cm.rainbow(np.linspace(0, 1, 1))\n",
        "    x = embeddings[:,0]\n",
        "    y = embeddings[:,1]\n",
        "    plt.scatter(x, y, c=colors, alpha=a, label=label)\n",
        "    for i, word in enumerate(words):\n",
        "        plt.annotate(word, alpha=0.3, xy=(x[i], y[i]), xytext=(5, 2), \n",
        "                     textcoords='offset points', ha='right', va='bottom', size=10)\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"hhh.png\", format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "tsne_plot_2d('Visualizing Embeddings using t-SNE', vector_embedded_2d, word_set, a=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5kaSkIEBvui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector_embedded_3d = TSNE(n_components=3).fit_transform(vectors)\n",
        "vector_embedded_3d.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwol3tZxCXfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj4JgotYgIiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tsne_plot_3d(title, label, embeddings, a=1):\n",
        "    fig = plt.figure()\n",
        "    ax = Axes3D(fig)\n",
        "    colors = cm.rainbow(np.linspace(0, 1, 1))\n",
        "    plt.scatter(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2], c=colors, alpha=a, label=label)\n",
        "    plt.legend(loc=4)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "tsne_plot_3d('Visualizing Embeddings using t-SNE', 'tasa_1.txt', vector_embedded_3d, a=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbStdR81hqG3",
        "colab_type": "text"
      },
      "source": [
        "**Remove stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkxl31icfHhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import nltk\n",
        "# nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWwiM2zmhxpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stopwords = nltk.corpus.stopwords.words('english')\n",
        "# cleaned_words = []\n",
        "\n",
        "# for word in words:\n",
        "#     if word not in stopwords:\n",
        "#         cleaned_words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
