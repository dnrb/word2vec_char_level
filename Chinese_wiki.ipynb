{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chinese_wiki.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnrb/word2vec_char_level/blob/master/Chinese_wiki.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZBE2c74iTqn",
        "colab_type": "code",
        "outputId": "c405f4ee-99eb-4403-c480-acd53c0350e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVShAdWOieLt",
        "colab_type": "code",
        "outputId": "dda8b3a2-19be-4fb2-e69f-c6496baaacee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "cd gdrive/My \\Drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dYS7VGBilzS",
        "colab_type": "text"
      },
      "source": [
        "**Gather All Text in the file**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEPbxBRsj7OP",
        "colab_type": "text"
      },
      "source": [
        "**Convert text to int**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MUO6ez8ipZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jieba\n",
        "import string\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUKNuKODisJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_read =  open(\"zhwiki-20190401_all.txt\", 'r')\n",
        "all_text_str = f_read.readlines()\n",
        "all_words = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-EYbZXGixPS",
        "colab_type": "text"
      },
      "source": [
        "**Chinese Word Segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4rQvTkEi0sk",
        "colab_type": "code",
        "outputId": "39ffeba1-b58b-4bab-9e54-f5e456a4516f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "for i in range(len(all_text_str)):\n",
        "    current_line = jieba.lcut(all_text_str[i].strip('\\n'))\n",
        "    all_words += current_line\n",
        "    \n",
        "len(all_words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.716 seconds.\n",
            "Prefix dict has been built succesfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81340161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBfLVQaujfVc",
        "colab_type": "code",
        "outputId": "897da781-2b67-4e44-98db-54866a6b5163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "all_words[-10:]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['谈判', '修改', '现有', '的', '条约', '这不应', '直接', '违背', '其', '精神']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcW9ZWcakApJ",
        "colab_type": "code",
        "outputId": "ed1f4e36-2743-42df-8248-98e4f921f11e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "words_set = set(all_words)\n",
        "len(words_set)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1687575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNZqOjtAkd9D",
        "colab_type": "text"
      },
      "source": [
        "**Convert text to int**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE906jcGniIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def str_to_int(lst):\n",
        "    counter = 0\n",
        "    new_list = []\n",
        "    existed = {}\n",
        "    \n",
        "    for string in lst:\n",
        "        if string not in existed:\n",
        "            existed[string] = counter\n",
        "            new_list.append(existed[string])\n",
        "            counter += 1\n",
        "        else:\n",
        "            new_list.append(existed[string])\n",
        "            \n",
        "    return new_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7yRwd5_oGFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2int = str_to_int(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b6VzicdmLaj",
        "colab_type": "code",
        "outputId": "7cc6bbbb-f089-4d07-afc2-c8573db16ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "min(word2int)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1MCjMpCmObf",
        "colab_type": "code",
        "outputId": "0c18c0d4-09a9-4adc-c1d8-b5573a2d6470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "max(word2int)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1687574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJXwKZXXmTGL",
        "colab_type": "text"
      },
      "source": [
        "**Set up the constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxY46f26mWkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_Train = 50\n",
        "n_Voc = max(word2int) + 1\n",
        "n_Corpus = len(word2int)\n",
        "WINDOW_SIZE = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXJxY79toOti",
        "colab_type": "code",
        "outputId": "b242ab50-010d-485a-ba35-ff282647c604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "n_Voc"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1687575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCJEVyNMeyGd",
        "colab_type": "text"
      },
      "source": [
        "**Initialize two arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJQ8yuhhexKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int):\n",
        "\n",
        "    X = np.zeros((n_Train, n_Voc))\n",
        "    Y = np.zeros((n_Train, n_Voc))\n",
        "\n",
        "    for i in range(n_Train):\n",
        "        j = np.random.choice(n_Corpus, 1)[0]\n",
        "\n",
        "        tw = word2int[j]\n",
        "\n",
        "        Y[i][tw] = 1\n",
        "\n",
        "        for k in range(j - WINDOW_SIZE, j + WINDOW_SIZE + 1):\n",
        "            if k != j and k >= 0 and k < n_Corpus:\n",
        "                cw = word2int[k]\n",
        "                X[i][cw] = 1\n",
        "                \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDEFW_v7oPXE",
        "colab_type": "code",
        "outputId": "867d0a2e-c68f-459a-fef4-2585178804dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SisXlsDQYhs",
        "colab_type": "code",
        "outputId": "c3b53568-d5a1-4499-fe64-c62381c38914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "ONE_HOT_DIM = n_Voc\n",
        "\n",
        "# # function to convert numbers to one hot vectors\n",
        "# def to_one_hot_encoding(data_point_index):\n",
        "#     one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
        "#     one_hot_encoding[data_point_index] = 1\n",
        "#     return one_hot_encoding\n",
        "\n",
        "# X = [] # input word\n",
        "# Y = [] # target word\n",
        "\n",
        "# for x, y in zip(df['input'], df['label']):\n",
        "#     X.append(to_one_hot_encoding(word2int[ x ]))\n",
        "#     Y.append(to_one_hot_encoding(word2int[ y ]))\n",
        "\n",
        "# # convert them to numpy arrays\n",
        "# X_train = np.asarray(X)\n",
        "# Y_train = np.asarray(Y)\n",
        "\n",
        "# making placeholders for X_train and Y_train\n",
        "x = tf.placeholder(tf.float64, shape=(None, ONE_HOT_DIM))\n",
        "y_label = tf.placeholder(tf.float64, shape=(None, ONE_HOT_DIM))\n",
        "\n",
        "# word embedding will be 2 dimension for 2d visualization\n",
        "EMBEDDING_DIM = 30\n",
        "\n",
        "# hidden layer: which represents word vector eventually\n",
        "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM], dtype=tf.float64))\n",
        "b1 = tf.Variable(tf.random_normal([1], dtype=tf.float64)) #bias\n",
        "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
        "\n",
        "# output layer\n",
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM], dtype=tf.float64))\n",
        "b2 = tf.Variable(tf.random_normal([1], dtype=tf.float64))\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
        "\n",
        "# loss function: cross entropy\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
        "\n",
        "# training operation(learning rate)\n",
        "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sUhj1mHiR_G",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPC4y_0biUKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "4cd80184-1fe0-4b37-bee3-5d99f0ffe00d"
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init) \n",
        "\n",
        "iteration = 20000\n",
        "for i in range(iteration + 1):\n",
        "    X, Y = data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int)\n",
        "    # input is X_train which is one hot encoded word\n",
        "    # label is Y_train which is one hot encoded neighbor word\n",
        "    sess.run(train_op, feed_dict={x: X, y_label: Y})\n",
        "    if i % 500 == 0:\n",
        "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X, y_label: Y}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0 loss is :  55.08156644510911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFz_OdtJiuqo",
        "colab_type": "text"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1j81pDCit4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "Z = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "Z_embedded = TSNE(n_components=2).fit_transform(Z)\n",
        "Z_embedded.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfzzBYgr-9El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = sess.run(W1 + b1)\n",
        "vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecEmg_b2Gsfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector_embedded_2d = TSNE(perplexity=100).fit_transform(vectors)\n",
        "vector_embedded_2d.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9-p5RdskEKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRqvW4jZGnkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tsne_plot_2d(label, embeddings, words=[], a=1):\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    colors = cm.rainbow(np.linspace(0, 1, 1))\n",
        "    x = embeddings[:,0]\n",
        "    y = embeddings[:,1]\n",
        "    plt.scatter(x, y, c=colors, alpha=a, label=label)\n",
        "    for i, word in enumerate(words):\n",
        "        plt.annotate(word, alpha=0.3, xy=(x[i], y[i]), xytext=(5, 2), \n",
        "                     textcoords='offset points', ha='right', va='bottom', size=10)\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"hhh.png\", format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "tsne_plot_2d('Visualizing Embeddings using t-SNE', vector_embedded_2d, word_set, a=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5kaSkIEBvui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector_embedded_3d = TSNE(n_components=3).fit_transform(vectors)\n",
        "vector_embedded_3d.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwol3tZxCXfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj4JgotYgIiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tsne_plot_3d(title, label, embeddings, a=1):\n",
        "    fig = plt.figure()\n",
        "    ax = Axes3D(fig)\n",
        "    colors = cm.rainbow(np.linspace(0, 1, 1))\n",
        "    plt.scatter(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2], c=colors, alpha=a, label=label)\n",
        "    plt.legend(loc=4)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "tsne_plot_3d('Visualizing Embeddings using t-SNE', 'tasa_1.txt', vector_embedded_3d, a=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbStdR81hqG3",
        "colab_type": "text"
      },
      "source": [
        "**Remove stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkxl31icfHhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import nltk\n",
        "# nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWwiM2zmhxpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stopwords = nltk.corpus.stopwords.words('english')\n",
        "# cleaned_words = []\n",
        "\n",
        "# for word in words:\n",
        "#     if word not in stopwords:\n",
        "#         cleaned_words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}