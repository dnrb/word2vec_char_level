# word2vec_char_level

Initial model works on the English corpus.

Finished the initial trainning on Chinese corpus.

Initial optimization of the model completed.


Credit:

https://github.com/minsuk-heo/python_tutorial/blob/master/data_science/nlp/word2vec_tensorflow.ipynb

https://github.com/savankoradiya/Google-Colab-Tutorial

https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA

https://www.tensorflow.org/tutorials/representation/word2vec

https://www.tensorflow.org/guide/embedding

https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d

https://github.com/minsuk-heo/python_tutorial/blob/master/data_science/nlp/word2vec_tensorflow.ipynb

https://distill.pub/2016/misread-tsne/

https://towardsdatascience.com/google-news-and-leo-tolstoy-visualizing-word2vec-word-embeddings-with-t-sne-11558d8bd4d


The Chinese corpus after preprocessed from Chinese wiki-dump is available at https://drive.google.com/file/d/1q2bbhhYas8ZCw9jRE09GprjxpOD0mU6r/view?usp=sharing
