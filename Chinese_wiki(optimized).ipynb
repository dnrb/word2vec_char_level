{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chinese_wiki(optimized).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnrb/word2vec_char_level/blob/master/Chinese_wiki(optimized).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZfFOJifvUNo",
        "colab_type": "code",
        "outputId": "856c111f-e20a-4dcd-9095-0b53b6231a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q3dYD1FvaRo",
        "colab_type": "code",
        "outputId": "2c0c6bbc-ee38-4aa6-ba06-17df7bdf93a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "cd gdrive/My \\Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0MUO6ez8ipZW",
        "colab": {}
      },
      "source": [
        "import jieba\n",
        "import string\n",
        "import re\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LUKNuKODisJD",
        "colab": {}
      },
      "source": [
        "f_read =  open(\"zhwiki-20190401_all.txt\", 'r')\n",
        "all_text_str = f_read.readlines()\n",
        "all_words = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R-EYbZXGixPS"
      },
      "source": [
        "**Chinese Word Segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K4rQvTkEi0sk",
        "outputId": "3271e7e5-3a96-405b-c420-616a9b03ac86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "for i in range(len(all_text_str)):\n",
        "    current_line = jieba.lcut(all_text_str[i].strip('\\n'))\n",
        "    all_words.extend(current_line)\n",
        "    \n",
        "len(all_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.877 seconds.\n",
            "Prefix dict has been built succesfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81340161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CBfLVQaujfVc",
        "outputId": "f66aea62-24a5-4cb3-aeaa-327df2eb35b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "all_words[-10:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['谈判', '修改', '现有', '的', '条约', '这不应', '直接', '违背', '其', '精神']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PcW9ZWcakApJ",
        "outputId": "d760aebc-848c-4eae-8178-ec61c2e256d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "words_set = set(all_words)\n",
        "len(words_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1687575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K5PZJpQ_0WE",
        "colab_type": "text"
      },
      "source": [
        "**Get the most common 100000 words in the corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dD1NBwk9Z--F",
        "colab": {}
      },
      "source": [
        "word_counters = collections.Counter(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrMpDEjzB6_c",
        "colab_type": "code",
        "outputId": "bd461f5e-6a5c-4c57-e1b4-755985d9d702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "most_common_words = set()\n",
        "\n",
        "for tup in word_counters.most_common(1000000):\n",
        "    most_common_words.add(tup[0])\n",
        "    \n",
        "len(most_common_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mapDlWZ25rHz",
        "colab_type": "code",
        "outputId": "a3a5ea7f-c01f-461f-d7cd-ca275841cf54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "'新影联' in most_common_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILZe5fGV4Hva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(all_words)):\n",
        "    if all_words[i] not in most_common_words:\n",
        "        all_words[i] = 'unknown'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddRfzRQi4oTN",
        "colab_type": "code",
        "outputId": "cdbfa091-60ba-4e92-801e-2a0a2ab7d2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "all_words.count('unknown')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "687575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MNZqOjtAkd9D"
      },
      "source": [
        "**Convert text to int**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QE906jcGniIO",
        "colab": {}
      },
      "source": [
        "def str_to_int(lst):\n",
        "    counter = 0\n",
        "    new_list = []\n",
        "    existed = {}\n",
        "    \n",
        "    for string in lst:\n",
        "        if string not in existed:\n",
        "            existed[string] = counter\n",
        "            new_list.append(existed[string])\n",
        "            counter += 1\n",
        "        else:\n",
        "            new_list.append(existed[string])\n",
        "            \n",
        "    return new_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m7yRwd5_oGFq",
        "colab": {}
      },
      "source": [
        "word2int = str_to_int(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_b6VzicdmLaj",
        "outputId": "532fa584-9487-4497-e9aa-5e4d9eab8f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "min(word2int)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D1MCjMpCmObf",
        "outputId": "e84aa7aa-0770-4fe1-ab42-37db6b7d33f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "max(word2int)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dJXwKZXXmTGL"
      },
      "source": [
        "**Set up the constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hxY46f26mWkz",
        "colab": {}
      },
      "source": [
        "n_Train = 50\n",
        "n_Voc = max(word2int) + 1\n",
        "n_Corpus = len(word2int)\n",
        "WINDOW_SIZE = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QXJxY79toOti",
        "outputId": "1a5f64d3-330c-4f79-ba58-f3217075c580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "n_Voc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCJEVyNMeyGd"
      },
      "source": [
        "**Initialize two arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yJQ8yuhhexKn",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int):\n",
        "\n",
        "    X = np.zeros((n_Train, n_Voc))\n",
        "    Y = np.zeros((n_Train, n_Voc))\n",
        "\n",
        "    for i in range(n_Train):\n",
        "        j = np.random.choice(n_Corpus, 1)[0]\n",
        "\n",
        "        tw = word2int[j]\n",
        "\n",
        "        Y[i][tw] = 1\n",
        "\n",
        "        for k in range(j - WINDOW_SIZE, j + WINDOW_SIZE + 1):\n",
        "            if k != j and k >= 0 and k < n_Corpus:\n",
        "                cw = word2int[k]\n",
        "                X[i][cw] = 1\n",
        "                \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EDEFW_v7oPXE",
        "outputId": "15df5331-ba6c-4af6-90e8-f73bb40db0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9SisXlsDQYhs",
        "outputId": "66a32607-939c-4214-a582-b489ba9f6451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "ONE_HOT_DIM = n_Voc\n",
        "\n",
        "# # function to convert numbers to one hot vectors\n",
        "# def to_one_hot_encoding(data_point_index):\n",
        "#     one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
        "#     one_hot_encoding[data_point_index] = 1\n",
        "#     return one_hot_encoding\n",
        "\n",
        "# X = [] # input word\n",
        "# Y = [] # target word\n",
        "\n",
        "# for x, y in zip(df['input'], df['label']):\n",
        "#     X.append(to_one_hot_encoding(word2int[ x ]))\n",
        "#     Y.append(to_one_hot_encoding(word2int[ y ]))\n",
        "\n",
        "# # convert them to numpy arrays\n",
        "# X_train = np.asarray(X)\n",
        "# Y_train = np.asarray(Y)\n",
        "\n",
        "# making placeholders for X_train and Y_train\n",
        "x = tf.placeholder(tf.float64, shape=(None, ONE_HOT_DIM))\n",
        "y_label = tf.placeholder(tf.float64, shape=(None, ONE_HOT_DIM))\n",
        "\n",
        "# word embedding will be 2 dimension for 2d visualization\n",
        "EMBEDDING_DIM = 30\n",
        "\n",
        "# hidden layer: which represents word vector eventually\n",
        "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM], dtype=tf.float64))\n",
        "b1 = tf.Variable(tf.random_normal([1], dtype=tf.float64)) #bias\n",
        "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
        "\n",
        "# output layer\n",
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM], dtype=tf.float64))\n",
        "b2 = tf.Variable(tf.random_normal([1], dtype=tf.float64))\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
        "\n",
        "# loss function: cross entropy\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
        "\n",
        "# training operation(learning rate)\n",
        "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_sUhj1mHiR_G"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPC4y_0biUKj",
        "outputId": "900c343e-f625-41ef-d4ef-aea0aa419126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init) \n",
        "\n",
        "iteration = 20000\n",
        "for i in range(iteration + 1):\n",
        "    X, Y = data_generate(n_Train, n_Voc, n_Corpus, WINDOW_SIZE, word2int)\n",
        "    # input is X_train which is one hot encoded word\n",
        "    # label is Y_train which is one hot encoded neighbor word\n",
        "    sess.run(train_op, feed_dict={x: X, y_label: Y})\n",
        "    if i % 500 == 0:\n",
        "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X, y_label: Y}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0 loss is :  54.98325766925586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lFz_OdtJiuqo"
      },
      "source": [
        "**Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r1j81pDCit4m",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "Z = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "Z_embedded = TSNE(n_components=2).fit_transform(Z)\n",
        "Z_embedded.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bfzzBYgr-9El",
        "colab": {}
      },
      "source": [
        "vectors = sess.run(W1 + b1)\n",
        "vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ecEmg_b2Gsfz",
        "colab": {}
      },
      "source": [
        "vector_embedded_2d = TSNE(perplexity=100).fit_transform(vectors)\n",
        "vector_embedded_2d.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K9-p5RdskEKx",
        "colab": {}
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qRqvW4jZGnkX",
        "colab": {}
      },
      "source": [
        "def tsne_plot_2d(label, embeddings, words=[], a=1):\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    colors = cm.rainbow(np.linspace(0, 1, 1))\n",
        "    x = embeddings[:,0]\n",
        "    y = embeddings[:,1]\n",
        "    plt.scatter(x, y, c=colors, alpha=a, label=label)\n",
        "    for i, word in enumerate(words):\n",
        "        plt.annotate(word, alpha=0.3, xy=(x[i], y[i]), xytext=(5, 2), \n",
        "                     textcoords='offset points', ha='right', va='bottom', size=10)\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"hhh.png\", format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "tsne_plot_2d('Visualizing Embeddings using t-SNE', vector_embedded_2d, word_set, a=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b5kaSkIEBvui",
        "colab": {}
      },
      "source": [
        "vector_embedded_3d = TSNE(n_components=3).fit_transform(vectors)\n",
        "vector_embedded_3d.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gwol3tZxCXfl",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fj4JgotYgIiV",
        "colab": {}
      },
      "source": [
        "def tsne_plot_3d(title, label, embeddings, a=1):\n",
        "    fig = plt.figure()\n",
        "    ax = Axes3D(fig)\n",
        "    colors = cm.rainbow(np.linspace(0, 1, 1))\n",
        "    plt.scatter(embeddings[:, 0], embeddings[:, 1], embeddings[:, 2], c=colors, alpha=a, label=label)\n",
        "    plt.legend(loc=4)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "tsne_plot_3d('Visualizing Embeddings using t-SNE', 'tasa_1.txt', vector_embedded_3d, a=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AbStdR81hqG3"
      },
      "source": [
        "**Remove stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jkxl31icfHhR",
        "colab": {}
      },
      "source": [
        "# import nltk\n",
        "# nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AWwiM2zmhxpE",
        "colab": {}
      },
      "source": [
        "# stopwords = nltk.corpus.stopwords.words('english')\n",
        "# cleaned_words = []\n",
        "\n",
        "# for word in words:\n",
        "#     if word not in stopwords:\n",
        "#         cleaned_words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}