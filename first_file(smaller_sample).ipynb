{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_file(smaller sample).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnrb/word2vec_char_level/blob/master/first_file(smaller_sample).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "e6V9UZs3ZgVz",
        "colab_type": "code",
        "outputId": "8c118dba-0c89-4655-e25c-8902f8c7063a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dnrb/word2vec_char_level.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'word2vec_char_level'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 35 (delta 14), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BYaN6r95aBe9",
        "colab_type": "code",
        "outputId": "345dcbba-045c-4b05-b0fe-7f7849cf0ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  word2vec_char_level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c79oIA2xaJZs",
        "colab_type": "code",
        "outputId": "45023e50-4c96-47a0-a6b5-1a6c7507e285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd word2vec_char_level"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/word2vec_char_level\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTMzA1TIaQW4",
        "colab_type": "code",
        "outputId": "893aaaab-c189-4c9a-f0f5-6fdb8a92fc75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first_file.ipynb  README.md  tasa_1.txt  tasa_2.txt  tasa_3.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_5CTTY49bs3B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Read the input file**"
      ]
    },
    {
      "metadata": {
        "id": "ZeokAW7caRsK",
        "colab_type": "code",
        "outputId": "f8d96ee6-e831-456e-a6c7-9b99c02bb7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file  = 'tasa_1.txt'\n",
        "filehandle = open(file)\n",
        "lines  = filehandle.readlines()\n",
        "len(lines)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "cDSBuQYLbnId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set up the corpus**"
      ]
    },
    {
      "metadata": {
        "id": "p3mAZUAxbkfX",
        "colab_type": "code",
        "outputId": "0e84d68b-caf3-4545-ea62-a73347a54272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "corpus = lines[:10]\n",
        "print(corpus)\n",
        "len(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['who were the first americans ?\\n', 'many , many years ago , perhaps 35,000 years ago , life was very different than it is today .\\n', 'at that time , the earth was in the grip of the last ice age .\\n', 'there were few people anywhere in the world , and none lived in the americas .\\n', 'people did live in asia , however .\\n', 'and some of them wandered into north america .\\n', 'the firstcomers did not know they had found a new continent .\\n', 'like all ice age peoples , they were hunters .\\n', 'they had to move from place to place in search of their food .\\n', 'sometimes they killed giant elephants called mammoths .\\n']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "QIKrn8PDcAeD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus = [x[:-1] for x in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snsuFqGTdVO4",
        "colab_type": "code",
        "outputId": "65dbb275-325f-4e81-b5c4-4363e31816cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['who were the first americans ?', 'many , many years ago , perhaps 35,000 years ago , life was very different than it is today .', 'at that time , the earth was in the grip of the last ice age .', 'there were few people anywhere in the world , and none lived in the americas .', 'people did live in asia , however .', 'and some of them wandered into north america .', 'the firstcomers did not know they had found a new continent .', 'like all ice age peoples , they were hunters .', 'they had to move from place to place in search of their food .', 'sometimes they killed giant elephants called mammoths .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PBRMeHvEd2XE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s1 = ['many, many years ago']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZkVDs_IgXaq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Gather every words in the corpus without duplication**"
      ]
    },
    {
      "metadata": {
        "id": "E_c8-FoNeo9Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "words = []\n",
        "\n",
        "for sentence in corpus:\n",
        "    \n",
        "    for word in sentence.split(' '):\n",
        "        \n",
        "        if word not in string.punctuation:\n",
        "            words.append(word)\n",
        "            \n",
        "words = set(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RrfxCx4AfF_1",
        "colab_type": "code",
        "outputId": "a5226f03-9231-49e5-e7fa-11b9f7ca37e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "AbStdR81hqG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Remove stop words**"
      ]
    },
    {
      "metadata": {
        "id": "Jkxl31icfHhR",
        "colab_type": "code",
        "outputId": "0fee1d19-8eab-4b37-a864-e129a5285bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "AWwiM2zmhxpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "cleaned_words = []\n",
        "\n",
        "for word in words:\n",
        "    if word not in stopwords:\n",
        "        cleaned_words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vjm-7azCxxHI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. replace number by tag"
      ]
    },
    {
      "metadata": {
        "id": "ZhA_JrEPh2lv",
        "colab_type": "code",
        "outputId": "ae8e1bd3-fd3b-4990-bb73-a0ab109a6747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "cell_type": "code",
      "source": [
        "cleaned_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['35,000',\n",
              " 'firstcomers',\n",
              " 'grip',\n",
              " 'mammoths',\n",
              " 'life',\n",
              " 'first',\n",
              " 'lived',\n",
              " 'today',\n",
              " 'move',\n",
              " 'search',\n",
              " 'none',\n",
              " 'years',\n",
              " 'called',\n",
              " 'different',\n",
              " 'america',\n",
              " 'wandered',\n",
              " 'elephants',\n",
              " 'ago',\n",
              " 'asia',\n",
              " 'however',\n",
              " 'many',\n",
              " 'north',\n",
              " 'know',\n",
              " 'live',\n",
              " 'americas',\n",
              " 'sometimes',\n",
              " 'killed',\n",
              " 'age',\n",
              " 'place',\n",
              " 'world',\n",
              " 'like',\n",
              " 'peoples',\n",
              " 'hunters',\n",
              " 'ice',\n",
              " 'perhaps',\n",
              " 'giant',\n",
              " 'americans',\n",
              " 'found',\n",
              " 'time',\n",
              " 'last',\n",
              " 'anywhere',\n",
              " 'food',\n",
              " 'people',\n",
              " 'new',\n",
              " 'earth',\n",
              " 'continent']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "DEPbxBRsj7OP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convert text to int**"
      ]
    },
    {
      "metadata": {
        "id": "GsrciQlRjrK_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(cleaned_words):\n",
        "    word2int[word] = i\n",
        "\n",
        "sentences = []\n",
        "for sentence in corpus:\n",
        "    sentences.append(sentence.split())\n",
        "    \n",
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "            if neighbor != word:\n",
        "                data.append([word, neighbor])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bz2sK5LwkBYn",
        "colab_type": "code",
        "outputId": "305568c8-d731-4223-f484-5b111691b482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7021
        }
      },
      "cell_type": "code",
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['who', 'were'],\n",
              " ['who', 'the'],\n",
              " ['were', 'who'],\n",
              " ['were', 'the'],\n",
              " ['were', 'first'],\n",
              " ['the', 'who'],\n",
              " ['the', 'were'],\n",
              " ['the', 'first'],\n",
              " ['the', 'americans'],\n",
              " ['first', 'were'],\n",
              " ['first', 'the'],\n",
              " ['first', 'americans'],\n",
              " ['first', '?'],\n",
              " ['americans', 'the'],\n",
              " ['americans', 'first'],\n",
              " ['americans', '?'],\n",
              " ['?', 'first'],\n",
              " ['?', 'americans'],\n",
              " ['many', ','],\n",
              " [',', 'many'],\n",
              " [',', 'many'],\n",
              " [',', 'years'],\n",
              " ['many', ','],\n",
              " ['many', 'years'],\n",
              " ['many', 'ago'],\n",
              " ['years', ','],\n",
              " ['years', 'many'],\n",
              " ['years', 'ago'],\n",
              " ['years', ','],\n",
              " ['ago', 'many'],\n",
              " ['ago', 'years'],\n",
              " ['ago', ','],\n",
              " ['ago', 'perhaps'],\n",
              " [',', 'years'],\n",
              " [',', 'ago'],\n",
              " [',', 'perhaps'],\n",
              " [',', '35,000'],\n",
              " ['perhaps', 'ago'],\n",
              " ['perhaps', ','],\n",
              " ['perhaps', '35,000'],\n",
              " ['perhaps', 'years'],\n",
              " ['35,000', ','],\n",
              " ['35,000', 'perhaps'],\n",
              " ['35,000', 'years'],\n",
              " ['35,000', 'ago'],\n",
              " ['years', 'perhaps'],\n",
              " ['years', '35,000'],\n",
              " ['years', 'ago'],\n",
              " ['years', ','],\n",
              " ['ago', '35,000'],\n",
              " ['ago', 'years'],\n",
              " ['ago', ','],\n",
              " ['ago', 'life'],\n",
              " [',', 'years'],\n",
              " [',', 'ago'],\n",
              " [',', 'life'],\n",
              " [',', 'was'],\n",
              " ['life', 'ago'],\n",
              " ['life', ','],\n",
              " ['life', 'was'],\n",
              " ['life', 'very'],\n",
              " ['was', ','],\n",
              " ['was', 'life'],\n",
              " ['was', 'very'],\n",
              " ['was', 'different'],\n",
              " ['very', 'life'],\n",
              " ['very', 'was'],\n",
              " ['very', 'different'],\n",
              " ['very', 'than'],\n",
              " ['different', 'was'],\n",
              " ['different', 'very'],\n",
              " ['different', 'than'],\n",
              " ['different', 'it'],\n",
              " ['than', 'very'],\n",
              " ['than', 'different'],\n",
              " ['than', 'it'],\n",
              " ['than', 'is'],\n",
              " ['it', 'different'],\n",
              " ['it', 'than'],\n",
              " ['it', 'is'],\n",
              " ['it', 'today'],\n",
              " ['is', 'than'],\n",
              " ['is', 'it'],\n",
              " ['is', 'today'],\n",
              " ['is', '.'],\n",
              " ['today', 'it'],\n",
              " ['today', 'is'],\n",
              " ['today', '.'],\n",
              " ['.', 'is'],\n",
              " ['.', 'today'],\n",
              " ['at', 'that'],\n",
              " ['at', 'time'],\n",
              " ['that', 'at'],\n",
              " ['that', 'time'],\n",
              " ['that', ','],\n",
              " ['time', 'at'],\n",
              " ['time', 'that'],\n",
              " ['time', ','],\n",
              " ['time', 'the'],\n",
              " [',', 'that'],\n",
              " [',', 'time'],\n",
              " [',', 'the'],\n",
              " [',', 'earth'],\n",
              " ['the', 'time'],\n",
              " ['the', ','],\n",
              " ['the', 'earth'],\n",
              " ['the', 'was'],\n",
              " ['earth', ','],\n",
              " ['earth', 'the'],\n",
              " ['earth', 'was'],\n",
              " ['earth', 'in'],\n",
              " ['was', 'the'],\n",
              " ['was', 'earth'],\n",
              " ['was', 'in'],\n",
              " ['was', 'the'],\n",
              " ['in', 'earth'],\n",
              " ['in', 'was'],\n",
              " ['in', 'the'],\n",
              " ['in', 'grip'],\n",
              " ['the', 'was'],\n",
              " ['the', 'in'],\n",
              " ['the', 'grip'],\n",
              " ['the', 'of'],\n",
              " ['grip', 'in'],\n",
              " ['grip', 'the'],\n",
              " ['grip', 'of'],\n",
              " ['grip', 'the'],\n",
              " ['of', 'the'],\n",
              " ['of', 'grip'],\n",
              " ['of', 'the'],\n",
              " ['of', 'last'],\n",
              " ['the', 'grip'],\n",
              " ['the', 'of'],\n",
              " ['the', 'last'],\n",
              " ['the', 'ice'],\n",
              " ['last', 'of'],\n",
              " ['last', 'the'],\n",
              " ['last', 'ice'],\n",
              " ['last', 'age'],\n",
              " ['ice', 'the'],\n",
              " ['ice', 'last'],\n",
              " ['ice', 'age'],\n",
              " ['ice', '.'],\n",
              " ['age', 'last'],\n",
              " ['age', 'ice'],\n",
              " ['age', '.'],\n",
              " ['.', 'ice'],\n",
              " ['.', 'age'],\n",
              " ['there', 'were'],\n",
              " ['there', 'few'],\n",
              " ['were', 'there'],\n",
              " ['were', 'few'],\n",
              " ['were', 'people'],\n",
              " ['few', 'there'],\n",
              " ['few', 'were'],\n",
              " ['few', 'people'],\n",
              " ['few', 'anywhere'],\n",
              " ['people', 'were'],\n",
              " ['people', 'few'],\n",
              " ['people', 'anywhere'],\n",
              " ['people', 'in'],\n",
              " ['anywhere', 'few'],\n",
              " ['anywhere', 'people'],\n",
              " ['anywhere', 'in'],\n",
              " ['anywhere', 'the'],\n",
              " ['in', 'people'],\n",
              " ['in', 'anywhere'],\n",
              " ['in', 'the'],\n",
              " ['in', 'world'],\n",
              " ['the', 'anywhere'],\n",
              " ['the', 'in'],\n",
              " ['the', 'world'],\n",
              " ['the', ','],\n",
              " ['world', 'in'],\n",
              " ['world', 'the'],\n",
              " ['world', ','],\n",
              " ['world', 'and'],\n",
              " [',', 'the'],\n",
              " [',', 'world'],\n",
              " [',', 'and'],\n",
              " [',', 'none'],\n",
              " ['and', 'world'],\n",
              " ['and', ','],\n",
              " ['and', 'none'],\n",
              " ['and', 'lived'],\n",
              " ['none', ','],\n",
              " ['none', 'and'],\n",
              " ['none', 'lived'],\n",
              " ['none', 'in'],\n",
              " ['lived', 'and'],\n",
              " ['lived', 'none'],\n",
              " ['lived', 'in'],\n",
              " ['lived', 'the'],\n",
              " ['in', 'none'],\n",
              " ['in', 'lived'],\n",
              " ['in', 'the'],\n",
              " ['in', 'americas'],\n",
              " ['the', 'lived'],\n",
              " ['the', 'in'],\n",
              " ['the', 'americas'],\n",
              " ['the', '.'],\n",
              " ['americas', 'in'],\n",
              " ['americas', 'the'],\n",
              " ['americas', '.'],\n",
              " ['.', 'the'],\n",
              " ['.', 'americas'],\n",
              " ['people', 'did'],\n",
              " ['people', 'live'],\n",
              " ['did', 'people'],\n",
              " ['did', 'live'],\n",
              " ['did', 'in'],\n",
              " ['live', 'people'],\n",
              " ['live', 'did'],\n",
              " ['live', 'in'],\n",
              " ['live', 'asia'],\n",
              " ['in', 'did'],\n",
              " ['in', 'live'],\n",
              " ['in', 'asia'],\n",
              " ['in', ','],\n",
              " ['asia', 'live'],\n",
              " ['asia', 'in'],\n",
              " ['asia', ','],\n",
              " ['asia', 'however'],\n",
              " [',', 'in'],\n",
              " [',', 'asia'],\n",
              " [',', 'however'],\n",
              " [',', '.'],\n",
              " ['however', 'asia'],\n",
              " ['however', ','],\n",
              " ['however', '.'],\n",
              " ['.', ','],\n",
              " ['.', 'however'],\n",
              " ['and', 'some'],\n",
              " ['and', 'of'],\n",
              " ['some', 'and'],\n",
              " ['some', 'of'],\n",
              " ['some', 'them'],\n",
              " ['of', 'and'],\n",
              " ['of', 'some'],\n",
              " ['of', 'them'],\n",
              " ['of', 'wandered'],\n",
              " ['them', 'some'],\n",
              " ['them', 'of'],\n",
              " ['them', 'wandered'],\n",
              " ['them', 'into'],\n",
              " ['wandered', 'of'],\n",
              " ['wandered', 'them'],\n",
              " ['wandered', 'into'],\n",
              " ['wandered', 'north'],\n",
              " ['into', 'them'],\n",
              " ['into', 'wandered'],\n",
              " ['into', 'north'],\n",
              " ['into', 'america'],\n",
              " ['north', 'wandered'],\n",
              " ['north', 'into'],\n",
              " ['north', 'america'],\n",
              " ['north', '.'],\n",
              " ['america', 'into'],\n",
              " ['america', 'north'],\n",
              " ['america', '.'],\n",
              " ['.', 'north'],\n",
              " ['.', 'america'],\n",
              " ['the', 'firstcomers'],\n",
              " ['the', 'did'],\n",
              " ['firstcomers', 'the'],\n",
              " ['firstcomers', 'did'],\n",
              " ['firstcomers', 'not'],\n",
              " ['did', 'the'],\n",
              " ['did', 'firstcomers'],\n",
              " ['did', 'not'],\n",
              " ['did', 'know'],\n",
              " ['not', 'firstcomers'],\n",
              " ['not', 'did'],\n",
              " ['not', 'know'],\n",
              " ['not', 'they'],\n",
              " ['know', 'did'],\n",
              " ['know', 'not'],\n",
              " ['know', 'they'],\n",
              " ['know', 'had'],\n",
              " ['they', 'not'],\n",
              " ['they', 'know'],\n",
              " ['they', 'had'],\n",
              " ['they', 'found'],\n",
              " ['had', 'know'],\n",
              " ['had', 'they'],\n",
              " ['had', 'found'],\n",
              " ['had', 'a'],\n",
              " ['found', 'they'],\n",
              " ['found', 'had'],\n",
              " ['found', 'a'],\n",
              " ['found', 'new'],\n",
              " ['a', 'had'],\n",
              " ['a', 'found'],\n",
              " ['a', 'new'],\n",
              " ['a', 'continent'],\n",
              " ['new', 'found'],\n",
              " ['new', 'a'],\n",
              " ['new', 'continent'],\n",
              " ['new', '.'],\n",
              " ['continent', 'a'],\n",
              " ['continent', 'new'],\n",
              " ['continent', '.'],\n",
              " ['.', 'new'],\n",
              " ['.', 'continent'],\n",
              " ['like', 'all'],\n",
              " ['like', 'ice'],\n",
              " ['all', 'like'],\n",
              " ['all', 'ice'],\n",
              " ['all', 'age'],\n",
              " ['ice', 'like'],\n",
              " ['ice', 'all'],\n",
              " ['ice', 'age'],\n",
              " ['ice', 'peoples'],\n",
              " ['age', 'all'],\n",
              " ['age', 'ice'],\n",
              " ['age', 'peoples'],\n",
              " ['age', ','],\n",
              " ['peoples', 'ice'],\n",
              " ['peoples', 'age'],\n",
              " ['peoples', ','],\n",
              " ['peoples', 'they'],\n",
              " [',', 'age'],\n",
              " [',', 'peoples'],\n",
              " [',', 'they'],\n",
              " [',', 'were'],\n",
              " ['they', 'peoples'],\n",
              " ['they', ','],\n",
              " ['they', 'were'],\n",
              " ['they', 'hunters'],\n",
              " ['were', ','],\n",
              " ['were', 'they'],\n",
              " ['were', 'hunters'],\n",
              " ['were', '.'],\n",
              " ['hunters', 'they'],\n",
              " ['hunters', 'were'],\n",
              " ['hunters', '.'],\n",
              " ['.', 'were'],\n",
              " ['.', 'hunters'],\n",
              " ['they', 'had'],\n",
              " ['they', 'to'],\n",
              " ['had', 'they'],\n",
              " ['had', 'to'],\n",
              " ['had', 'move'],\n",
              " ['to', 'they'],\n",
              " ['to', 'had'],\n",
              " ['to', 'move'],\n",
              " ['to', 'from'],\n",
              " ['move', 'had'],\n",
              " ['move', 'to'],\n",
              " ['move', 'from'],\n",
              " ['move', 'place'],\n",
              " ['from', 'to'],\n",
              " ['from', 'move'],\n",
              " ['from', 'place'],\n",
              " ['from', 'to'],\n",
              " ['place', 'move'],\n",
              " ['place', 'from'],\n",
              " ['place', 'to'],\n",
              " ['to', 'from'],\n",
              " ['to', 'place'],\n",
              " ['to', 'place'],\n",
              " ['to', 'in'],\n",
              " ['place', 'to'],\n",
              " ['place', 'in'],\n",
              " ['place', 'search'],\n",
              " ['in', 'to'],\n",
              " ['in', 'place'],\n",
              " ['in', 'search'],\n",
              " ['in', 'of'],\n",
              " ['search', 'place'],\n",
              " ['search', 'in'],\n",
              " ['search', 'of'],\n",
              " ['search', 'their'],\n",
              " ['of', 'in'],\n",
              " ['of', 'search'],\n",
              " ['of', 'their'],\n",
              " ['of', 'food'],\n",
              " ['their', 'search'],\n",
              " ['their', 'of'],\n",
              " ['their', 'food'],\n",
              " ['their', '.'],\n",
              " ['food', 'of'],\n",
              " ['food', 'their'],\n",
              " ['food', '.'],\n",
              " ['.', 'their'],\n",
              " ['.', 'food'],\n",
              " ['sometimes', 'they'],\n",
              " ['sometimes', 'killed'],\n",
              " ['they', 'sometimes'],\n",
              " ['they', 'killed'],\n",
              " ['they', 'giant'],\n",
              " ['killed', 'sometimes'],\n",
              " ['killed', 'they'],\n",
              " ['killed', 'giant'],\n",
              " ['killed', 'elephants'],\n",
              " ['giant', 'they'],\n",
              " ['giant', 'killed'],\n",
              " ['giant', 'elephants'],\n",
              " ['giant', 'called'],\n",
              " ['elephants', 'killed'],\n",
              " ['elephants', 'giant'],\n",
              " ['elephants', 'called'],\n",
              " ['elephants', 'mammoths'],\n",
              " ['called', 'giant'],\n",
              " ['called', 'elephants'],\n",
              " ['called', 'mammoths'],\n",
              " ['called', '.'],\n",
              " ['mammoths', 'elephants'],\n",
              " ['mammoths', 'called'],\n",
              " ['mammoths', '.'],\n",
              " ['.', 'called'],\n",
              " ['.', 'mammoths']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "o2cywu4ZkfWC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}